# Статистические тесты: Полное описание

## 1. Chi-Square Test (Критерий Хи-квадрат)

### Когда использовать
Когда сравниваешь **категориальные** (бинарные) переменные между двумя группами.

**Примеры в нашем проекте:**
- Добавил товар в корзину (Yes/No) → CR_add
- Кликнул на рекламу (Yes/No) → CTR

### Формула

```
χ² = Σ [(Observed - Expected)² / Expected]
```

где:
- **Observed** — наблюдаемое количество (реальные данные)
- **Expected** — ожидаемое количество (при нулевой гипотезе)

### Таблица 2x2

|  | Added | Not Added | Total |
|---|-------|-----------|-------|
| Control | a | b | a+b |
| Test | c | d | c+d |
| Total | a+c | b+d | n |

### Расчёт в Python

```python
from scipy.stats import chi2_contingency

# Таблица сопряженности
contingency_table = [[a, b], [c, d]]

# Выполнить тест
chi2, p_value, dof, expected = chi2_contingency(contingency_table)

print(f"Chi-square: {chi2:.4f}")
print(f"P-value: {p_value:.4f}")
```

### Интерпретация
- **p < 0.05** → группы различаются статистически значимо ✅
- **p ≥ 0.05** → нет статистически значимого различия ❌

---

## 2. Welch's t-test (t-тест Уэлча)

### Когда использовать
Когда сравниваешь **непрерывные** переменные (числовые значения, средние показатели).

**Примеры в нашем проекте:**
- ARPU (средняя выручка на пользователя)
- Средняя выручка на группу

### Формула

```
t = (μ₁ - μ₂) / √(s₁²/n₁ + s₂²/n₂)
```

где:
- **μ** — среднее значение
- **s²** — дисперсия
- **n** — размер выборки

### Преимущества Welch's t-test
- ✅ Не требует равенства дисперсий между группами
- ✅ Более надёжен при разных размерах выборок
- ✅ Робастен к нарушениям нормальности

### Расчёт в Python

```python
from scipy.stats import ttest_ind

# Выручка в контроле и тесте
revenue_control = [100, 150, 200, ...]
revenue_test = [120, 160, 190, ...]

# Выполнить Welch's t-test
t_stat, p_value = ttest_ind(revenue_control, revenue_test, equal_var=False)

print(f"t-statistic: {t_stat:.4f}")
print(f"P-value: {p_value:.4f}")
```

### Степени свободы
```
df ≈ (s₁²/n₁ + s₂²/n₂)² / ((s₁²/n₁)²/(n₁-1) + (s₂²/n₂)²/(n₂-1))
```

---

## 3. Размер эффекта (Effect Size)

### Важность
p-value показывает **значимость**, но не показывает **масштаб эффекта**.

### Cohen's h (для бинарных переменных)

```
h = 2 * (arcsin(√p₁) - arcsin(√p₂))
```

Интерпретация:
- h < 0.2 → малый эффект
- 0.2 ≤ h < 0.5 → средний эффект
- h ≥ 0.5 → большой эффект

### Cohen's d (для непрерывных переменных)

```
d = (μ₁ - μ₂) / √((s₁² + s₂²) / 2)
```

Интерпретация:
- d < 0.2 → малый эффект
- 0.2 ≤ d < 0.8 → средний эффект
- d ≥ 0.8 → большой эффект

### Расчёт в Python

```python
# Cohen's h
import math
h = 2 * (math.asin(math.sqrt(p1)) - math.asin(math.sqrt(p2)))

# Cohen's d
d = (mean1 - mean2) / math.sqrt((std1**2 + std2**2) / 2)

print(f"Cohen's h: {h:.4f}")
print(f"Cohen's d: {d:.4f}")
```

---

## 4. Доверительные интервалы (Confidence Intervals)

### 95% Confidence Interval

Для **конверсии** (бинарная переменная):
```
CI = p ± 1.96 * √(p(1-p)/n)
```

Для **ARPU** (непрерывная переменная):
```
CI = μ ± 1.96 * (s / √n)
```

### Интерпретация
- Если CI не включает 0 → результат статистически значимый ✅
- Если CI включает 0 → результат НЕ значимый ❌

### Пример
```
CR_add Control: 2.84% [CI: 2.76% - 2.92%]
CR_add Test:    2.85% [CI: 2.77% - 2.93%]

→ Интервалы перекрываются → нет значимого различия
```

---

## 5. Мощность теста (Statistical Power)

**Статистическая мощность** = 1 - β  
где β = вероятность ошибки Type II (ложноотрицательный результат)

### Пороги
- **80%** — стандарт в индустрии ✅
- **90%** — высокая мощность
- <80% — рискованно

### Как влияет на размер выборки
```
n ∝ (Zα/2 + Zβ)² * (σ₁² + σ₂²) / (μ₁ - μ₂)²
```

Чем больше нужна мощность → тем больше нужна выборка.

---

## 6. Ошибки в гипотезном тестировании

### Type I Error (α - ложноположительный результат)
- "Находим эффект, когда его нет"
- p < 0.05 → отвергаем H₀ (но H₀ может быть верна)
- α = 0.05 (5% вероятность ошибки)

### Type II Error (β - ложноотрицательный результат)
- "Не находим эффект, когда он есть"
- p ≥ 0.05 → не отвергаем H₀ (но H₀ может быть неверна)
- β = 0.20 (20% вероятность ошибки) → Power = 80%

### Trade-off
↓ α → ↑ n (нужна большая выборка)  
↓ β → ↑ n (нужна большая выборка)

---

## 7. Множественные сравнения (Multiple Testing)

### Проблема
Когда проводишь много тестов, вероятность ошибки Type I растёт.

Например, при 20 независимых тестах с α=0.05:
```
P(хотя бы одна ошибка) = 1 - (1 - 0.05)²⁰ ≈ 0.64
```

### Решение: Bonferroni Correction
```
α_adjusted = α / m
```
где m = количество тестов

**Пример:** 5 тестов → α_adjusted = 0.05 / 5 = 0.01

⚠️ **Внимание:** Bonferroni очень консервативен (может пропустить реальные эффекты).

---

## 8. Практический пример из проекта

### Тест CR_add (День 1 vs. полный период)

**День 1 результаты:**
```
Control: 111 добавлений из 7,893 пользователей → 1.40%
Test:    117 добавлений из 7,453 пользователей → 1.57%

χ² = 6.76
p-value = 0.0093 < 0.05 ✅ ЗНАЧИМО!

Cohen's h = 0.054 (малый эффект, но значимый)
CI: [0.51%, +12.1%]
```

**Полный период:**
```
Control: 11,416 из 201,630 → 2.84%
Test:    11,417 из 199,630 → 2.85%

χ² = 0.07
p-value = 0.791 > 0.05 ❌ НЕ значимо

Cohen's h = 0.003 (практически нет эффекта)
```

---

## Источники

- [SciPy Statistics](https://docs.scipy.org/doc/scipy/reference/stats.html)
- Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences
- [A/B Testing Statistical Significance](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)